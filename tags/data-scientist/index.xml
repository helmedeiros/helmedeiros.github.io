<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Scientist on Helio Medeiros</title>
    <link>https://helmedeiros.github.io//tags/data-scientist/</link>
    <description>Recent content in Data Scientist on Helio Medeiros</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Apr 2014 21:27:50 +0000</lastBuildDate>
    
	<atom:link href="https://helmedeiros.github.io//tags/data-scientist/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Um Sistema de recomendação de produtos baseado em grafos: Titan, Cassandra, Redis e Hadoop em produção</title>
      <link>https://helmedeiros.github.io//2014/04/10/um-sistema-de-recomendacao-de-produtos-baseado-em-grafos-titan-cassandra-redis-e-hadoop-em-producao/</link>
      <pubDate>Thu, 10 Apr 2014 21:27:50 +0000</pubDate>
      
      <guid>https://helmedeiros.github.io//2014/04/10/um-sistema-de-recomendacao-de-produtos-baseado-em-grafos-titan-cassandra-redis-e-hadoop-em-producao/</guid>
      <description>Big data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so everyone claims they are doing it..
 As maiores empresas estão tentando descobrir e ajudar a empresa a a interseção entre oque as pessoas querem, e o que a empresa quer que as pessoas comprem. Neste contexto o Andre Fatala e o Renato Pedigoni, trazem um case da Magazine Luiza.</description>
    </item>
    
    <item>
      <title>Data Science em Tempo Real com Storm</title>
      <link>https://helmedeiros.github.io//2014/04/10/data-science-em-tempo-real-com-storm/</link>
      <pubDate>Thu, 10 Apr 2014 18:32:54 +0000</pubDate>
      
      <guid>https://helmedeiros.github.io//2014/04/10/data-science-em-tempo-real-com-storm/</guid>
      <description>Hoje sabemos que temos um monte de dados, e dai descobrimos que estes dados não é só uma caixinha mais várias, você aplica processadores estatísticos, algo de inteligência artificial, e no final temos uma saída com os dados que são esperados.
Em 2012 as aplicações da Fabiane eram mais ou menos, um acumulo de dados e que no final estes eram processados em batch com uma saída. Parece que durante muito tempo este processamento ou a necessidade em relacioná-los e processá-los era menor.</description>
    </item>
    
    <item>
      <title>Building a Data Science Program at NASA/JPL with Visual Analytics</title>
      <link>https://helmedeiros.github.io//2014/04/10/building-a-data-science-program-at-nasajpl-with-visual-analytics/</link>
      <pubDate>Thu, 10 Apr 2014 13:54:41 +0000</pubDate>
      
      <guid>https://helmedeiros.github.io//2014/04/10/building-a-data-science-program-at-nasajpl-with-visual-analytics/</guid>
      <description>Explorar o universo gera um conjunto enorme de dados. E quando estamos falando sobre os dados que nos deparamos o tempo todo, estamos falando com um conjunto de satélites que estão processando e enviando dados dia e noite durante todo o dia.
As tecnologias de troca de dados assim como as suas fontes são cada vez maiores e diversas, a troca de informações por lasers está quase acontecendo, e como podemos olhar estes dados de perto?</description>
    </item>
    
  </channel>
</rss>